# 🛣️ AI 기반 포트홀 탐지: 2025 SSAFY AI 챌린지 최종 보고서

> **"도로 위 숨은 위협, 포트홀을 찾아내는 AI 탐정"** - YOLOv5 & v8 기반 객체 탐지 모델 개발 및 성능 최적화 여정

**[ 챌린지 최종 순위: 수상 ✨ ]**

---

### 📚 목차
1.  [**프로젝트 개요**](#1-프로젝트-개요)
2.  [**핵심 목표 및 성과**](#2-핵심-목표-및-성과)
3.  [**최종 결과 요약**](#3-최종-결과-요약)
4.  [**전체 워크플로우**](#4-전체-워크플로우)
5.  [**실험 설계 및 과정**](#5-실험-설계-및-과정)
    -   [5.1. 데이터 분석 및 전처리 전략](#51-데이터-분석-및-전처리-전략)
    -   [5.2. 실험 A: YOLOv5s - 강인한 Augmentation 중심 접근](#52-실험-a-yolov5s---강인한-augmentation-중심-접근)
    -   [5.3. 실험 B: YOLOv8n - 최신 아키텍처 및 고해상도 전략](#53-실험-b-yolov8n---최신-아키텍처-및-고해상도-전략)
6.  [**성능 분석 및 고찰**](#6-성능-분석-및-고찰)
7.  [**핵심 코드 리뷰**](#7-핵심-코드-리뷰)
    -   [7.1. 모델 학습](#71-모델-학습)
    -   [7.2. 추론 및 후처리](#72-추론-및-후처리)
8.  [**사용한 기술 스택**](#8-사용한-기술-스택)
9.  [**프로젝트 회고 및 배운 점**](#9-프로젝트-회고-및-배운-점)

---

## 1. 프로젝트 개요

본 프로젝트는 **SSAFY AI Challenge 2025**의 일환으로, "AI 기반 포트홀 탐지"를 주제로 진행되었습니다. 도로 위 포트홀은 차량 파손 및 교통사고의 주요 원인으로, 이를 신속하고 정확하게 탐지하는 기술은 자율주행 및 도로 유지보수 시스템의 핵심 요소입니다.

- **대회 기간:** 2025년 4월 23일 ~ 2025년 5월 6일
- **주요 과제:** 제공된 도로 이미지 데이터셋을 활용하여 포트홀 객체를 탐지하는 AI 모델 개발
- **평가 지표:** $mAP@0.5$ (mean Average Precision at IoU 0.5)
- **도전의 의의:** 기존의 인력 기반 점검 방식의 한계를 극복하고, AI를 통해 **자동화되고, 정확하며, 비용 효율적인** 도로 안전 관리 솔루션을 구현하는 가능성을 탐색하는 데 있습니다.

## 2. 핵심 목표 및 성과 및 팀 내 역할

### 🎯 목표

1.  **YOLO 계열 모델 활용:** 객체 탐지 분야에서 검증된 YOLO(You Only Look Once) 모델을 중심으로 문제에 접근합니다.
2.  **데이터 중심 전략:** 성능 향상을 위해 데이터의 특성을 깊이 분석하고, 효과적인 데이터 증강(Data Augmentation) 및 전처리 기법을 적용합니다.
3.  **체계적인 실험:** 다양한 모델 아키텍처, 하이퍼파라미터, 이미지 해상도 등을 조합하며 최적의 솔루션을 도출합니다.
4.  **성능 목표:** 평가 지표인 **$mAP@0.5$ 기준 96% 이상**을 달성하여 상위권에 입상하는 것을 목표로 설정했습니다.

### ✨ 주요 성과

- **최종 $mAP@0.5$ 점수 96.333% 달성**으로 챌린지에서 성공적으로 수상하였습니다.
- 두 가지 주요 실험(YOLOv5s, YOLOv8n)을 통해 각기 다른 접근 방식의 장단점을 비교 분석하고, 최적의 조합을 찾아냈습니다.
- 데이터 증강, 특히 **조명 변화에 대한 강인함**을 확보하는 전략이 성능 향상에 결정적이었음을 입증했습니다.

![image](https://github.com/user-attachments/assets/7c75a584-3961-4690-ac03-521767fbe1eb)

![image](https://github.com/user-attachments/assets/a10e0b91-0c81-438b-9eaf-c41a6582797a)


### 🙋‍♂️ 팀 구성 및 역할

-   **팀원:** 김연주(본인), 유준일, 박희진, 임재은
-   **주요 기여 및 역할 분담:**
    -   **프로젝트 총괄 및 기획 (Project Lead):** [김연주]
    -   **추가 데이터 수집** [박희진]
    -   **추가 데이터 라벨링** [유준일, 임재은] 
    -   **데이터 분석 및 시각화 (EDA):** [김연주]
    -   **데이터 전처리 및 증강 파이프라인 구축:** [김연주]
    -   **AI 모델 선정 및 실험 설계:** [김연주]
        -   YOLOv5, YOLOv8(n,s,m,l) 모델 비교 실험
        -   하이퍼파라미터 튜닝 전략 수립
    -   **핵심 모델 학습 및 검증:** [김연주]
    -   **후처리 로직 구현 및 최종 제출:** [김연주]
    -   **최종 보고서(README) 작성:** [김연주]


## 3. 최종 결과 요약

| 실험 | 모델 아키텍처 | 핵심 전략 | 최종 mAP@0.5 |
| :--- | :--- | :--- | :--- |
| **실험 A** | `YOLOv8m` | **풀스펙 Augmentation + 이미지 리사이즈(1024) + 밝기 조절** | **🏆 96.333%** |
| **실험 B** | `YOLOv8s` | 고해상도(1024) 학습 + 기본 Augmentation | 96.266% |
| **실험 C** | `YOLOv8m` | 기본 설정 (Baseline), Augmentation 최소화 | 94.512% |
| **실험 D** | `YOLOv8s` | 기본 설정 (Baseline), `s` 모델 테스트 | 94.281% |
| **실험 E** | `YOLOv8n` | 가장 작은 `n` 모델 성능 테스트 (속도 중심) | 93.845% |
| **실험 F** | `YOLOv8l` | 대형 `l` 모델, 과적합(Overfitting) 경향 확인 | 92.155% |
| **실험 G** | `YOLOv8s` | Learning Rate 스케줄러 변경 (Cosine → Linear) | 91.581% |
| **실험 H** | `YOLOv8s` | Optimizer 변경 (AdamW → SGD) | 90.320% |
| **실험 I** | `YOLOv8m` | 고급 Augmentation 적용 (Mosaic, MixUp 강화) | 90.218% |
| **실험 J** | `YOLOv8m` | Augmentation 중 **밝기 조절 전략 제외** | 89.974% |
| **실험 K** | `YOLOv8s` | 고해상도(1024) + **풀스펙 Augmentation** | 88.289% |
| **실험 L** | `YOLOv8s` | 사전 학습 가중치 미사용 (Train From Scratch) | 87.140% |
| **실험 M** | `YOLOv8s` | Albumentations 외부 라이브러리 도입 테스트 | 70.110% |
| **실험 N** | `YOLOv5s` | YOLOv5 아키텍처 기본 성능 테스트 | 45.882% |
| **실험 O** | `YOLOv5s` | **YOLOv5s + 풀스펙 Augmentation 적용** | 45.315% |
| **실험 P** | `YOLOv5s` | Epoch 증가 및 조기 종료(Patience) 완화 | 45.250% |

최종적으로 **실험 A**의 `YOLOv8m` 기반 모델이 미세한 차이로 더 높은 성능을 기록했으며, 이 모델의 예측 결과를 최종 제출물로 선택했습니다.

---

## 4. 전체 워크플로우

본 프로젝트는 다음과 같은 체계적인 단계로 진행되었습니다.

1.  🎯 **문제 정의 및 목표 설정**
2.  → 📊 **데이터 분석 (EDA)**
3.  → ✂️ **데이터 전처리 및 증강 전략 수립**
4.  → 🧪 **실험 설계 (Model & Hyperparameter)**
5.  → 🏋️‍♂️ **모델 학습 및 검증 (실험 A, B 등 진행)**
6.  → 📈 **성능 평가 및 분석**
7.  → 🚀 **추론 및 후처리**
8.  → 📤 **최종 결과 제출**
   
---

## 5\. 실험 설계 및 과정

단순히 모델을 학습시키는 것을 넘어, 데이터의 특성을 깊이 이해하고 가설을 세워 검증하는 방식으로 실험을 설계했습니다.

### 5.1. 데이터 분석 및 전처리 전략

  - **초기 데이터 분석 (EDA):**

      - **이미지 크기:** 다양한 해상도의 이미지가 혼재되어 있어, 모델 학습 시 입력 크기를 통일하는 과정이 필수적이었습니다.
      - **조명 조건:** 주간, 야간, 그림자 등 다양한 조명 조건의 이미지가 포함되어 있었습니다. 이는 모델이 특정 밝기 값에 과적합되지 않도록 하는 것이 중요함을 시사했습니다.
      - **포트홀 특징:** 크기, 형태, 도로 내 위치가 매우 다양하여, 모델이 강인함(Robustness)을 갖도록 데이터 증강 전략을 수립했습니다.

  - **데이터 증강 (Data Augmentation):**

    > **가설: 조명과 같은 환경 변화에 강인한 모델이 더 높은 성능을 보일 것이다.**

    이를 위해 `Albumentations` 라이브러리를 적극 활용하여 다음과 같은 증강 기법을 적용했습니다.

      - `RandomBrightnessContrast`: 다양한 조명 조건을 시뮬레이션하여 모델의 일반화 성능을 높입니다.
      - `HorizontalFlip`, `VerticalFlip`: 포트홀의 방향성에 대한 불변성을 학습시킵니다.
      - `ShiftScaleRotate`: 객체의 위치, 크기, 회전 변화에 대응하는 능력을 강화합니다.
      - **YOLO 기본 증강:** `ultralytics` 프레임워크에 내장된 **Mosaic**와 **MixUp** 증강을 활성화하여 다양한 이미지 조각을 조합, 모델이 부분적인 객체나 복잡한 배경 속에서도 포트홀을 잘 탐지하도록 유도했습니다.

### 5.2. 실험 A: YOLOv8m - 강인한 Augmentation 중심 접근

  - **모델:** `YOLOv8m`. v8 시리즈는 안정성과 속도, 정확도 간의 균형이 뛰어나 베이스라인 및 성능 최적화에 적합하다고 판단했습니다.
  - **핵심 전략:**
    1.  **강력한 데이터 증강:** 위에서 설계한 `Albumentations` 파이프라인을 적용했습니다. 특히 `RandomBrightnessContrast`의 강도를 높게 설정했습니다.
    2.  **이미지 리사이즈:** 모든 이미지를 `1024x1024`으로 통일하여 학습 안정성을 확보했습니다.
  - **주요 하이퍼파라미터:**
      - `imgsz`: 1024
      - `batch`: 16
      - `epochs`: 100
      - `patience`: 20 (조기 종료)
      - `conf`:0.1(최대한 많은 콘텐츠 찾아내기)
  - **결과:** **$mAP@0.5$ 96.333%**. 이 실험은 우리의 가설대로, 강력한 데이터 증강이 포트홀 데이터셋의 다양한 환경 변수를 극복하는 데 매우 효과적이었음을 증명했습니다.

### 5.3. 실험 B: YOLOv8s - 최신 아키텍처 및 고해상도 전략

  - **모델:** `YOLOv8s`. Anchor-free 방식과 개선된 백본을 특징으로 하는 최신 아키텍처의 성능을 확인하고자 했습니다.
  - **핵심 전략:**
    1.  **고해상도 학습:** 작은 포트홀 객체의 탐지 성능을 높이기 위해 이미지 해상도를 `1024x1024`로 설정했습니다.
    2.  **기본 Augmentation 활용:** YOLOv8의 기본 증강 성능을 신뢰하고, `Albumentations`는 최소한으로 적용했습니다.
  - **주요 하이퍼파라미터:**
      - `imgsz`: 1024
      - `batch`: 8 (메모리 제약으로 감소)
      - `epochs`: 100
      - `conf`:0.1 (최대한 많은 콘텐츠 찾아내기)
  - **결과:** **$mAP@0.5$ 96.266%**. 고해상도 전략은 분명 효과가 있었으나, 실험 A의 정교한 Augmentation 전략보다는 성능이 소폭 낮았습니다.

## 6\. 성능 분석 및 고찰

  - **실험 A가 더 우수했던 이유:** 포트홀 데이터셋은 객체의 복잡성보다는 \*\*'어떤 환경에서 찍혔는가'\*\*가 더 큰 변수였습니다. YOLOv5s와 결합된 강력한 밝기/대비 증강은 이러한 환경적 노이즈를 효과적으로 극복하여, 모델이 포트홀의 본질적인 형태 특징에 더 집중하도록 만들었습니다.
  - **고해상도의 장단점:** 실험 B의 고해상도 접근은 작은 객체를 탐지하는 데 유리했지만, 메모리 사용량 증가로 배치 사이즈가 줄어들어 학습 안정성에 영향을 미쳤을 수 있습니다. 또한, 데이터 증강의 부재가 다양한 조명 조건에 대한 일반화 성능을 다소 저해했을 가능성이 있습니다.
  - **결론:** 본 챌러니에서는 **최신 아키텍처나 고해상도 이미지보다, 데이터의 특성을 정확히 파악하고 그에 맞는 데이터 증강 전략을 수립하는 것이 성능 향상의 핵심 열쇠**였습니다.

## 7\. 핵심 코드 리뷰

프로젝트의 재현성과 이해를 돕기 위해 핵심 로직의 코드 일부를 공유합니다.

### 7.1. 모델 학습

`ultralytics` 라이브러리를 사용하여 간결하지만 강력한 학습 파이프라인을 구축했습니다.

```python
# YOLOv8m 모델 로드 (실험 A 기준)
from ultralytics import YOLO

# 사전 학습된 YOLOv8m 모델을 로드합니다.
model = YOLO('yolov8m.pt')

# 모델 학습 실행
# data: 커스텀 데이터셋 설정 파일 (yaml)
# epochs: 전체 데이터셋 반복 학습 횟수
# patience: 검증 성능이 개선되지 않을 때 조기 종료까지 기다릴 epoch 수
# batch: 한 번의 스텝에서 사용할 이미지 수
# imgsz: 학습에 사용할 이미지 크기
results = model.train(
    data='./pothole_dataset.yaml',
    epochs=100,
    patience=20,
    batch=16,
    imgsz=640,
    project='pothole_detection',
    name='exp_yolov8m_aug'
)
```

### 7.2. 추론 및 후처리

대회 규정에 따라, 각 이미지에서 **가장 신뢰도(confidence)가 높은 단 하나의 바운딩 박스만** 제출해야 했습니다. 이를 위한 후처리 로직이 중요했습니다.

```python
import pandas as pd
import torch
from tqdm import tqdm
import os

# ... (모델 및 테스트 데이터 로더 설정) ...

submission_rows = []
# test_image_paths는 테스트 이미지 경로 리스트라고 가정합니다.
for image_path in tqdm(test_image_paths):
    image_id = os.path.basename(image_path)
    
    # 모델 추론 수행
    results = model(image_path, verbose=False)
    
    # 결과에서 바운딩 박스 정보 추출
    boxes = results[0].boxes
    
    # 탐지된 객체가 하나 이상 있는 경우
    if len(boxes) > 0:
        # 가장 높은 confidence 값을 가진 박스의 인덱스를 찾음
        confidences = boxes.conf
        best_idx = torch.argmax(confidences)
        
        # 해당 박스의 클래스 ID와 정규화된 좌표(xywhn)를 추출
        cls_id = int(boxes.cls[best_idx].item())
        cx, cy, w, h = boxes.xywhn[best_idx].tolist()

        submission_rows.append({
            "ImageId": image_id,
            "ClassId": cls_id,
            "X": round(cx, 6), "Y": round(cy, 6),
            "Width": round(w, 6), "Height": round(h, 6),
        })
    else:
        # 포트홀이 탐지되지 않은 경우, 규정에 따라 0 값으로 제출
        submission_rows.append({
            "ImageId": image_id, "ClassId": 0,
            "X": 0, "Y": 0, "Width": 0, "Height": 0,
        })

# 최종 제출 파일(CSV) 생성
submission_df = pd.DataFrame(submission_rows)
submission_df.to_csv('submission.csv', index=False)

print("제출 파일 생성이 완료되었습니다.")
```

이 로직은 대회 규정을 정확히 준수하여 점수 손실을 방지하는 데 결정적인 역할을 했습니다.

## 8\. 사용한 기술 스택

  - **언어:** `Python`
  - **핵심 라이브러리:**
      - `PyTorch`: 딥러닝 프레임워크
      - `ultralytics`: YOLOv8 모델 구현 및 학습/추론
      - `OpenCV-Python`: 이미지 로딩 및 기본 처리
      - `Albumentations`: 고급 데이터 증강
  - **데이터 분석 및 시각화:** `Pandas`, `Matplotlib`
  - **개발 환경:** `Google Colab` (GPU: NVIDIA T4/P100), `Jupyter Notebook`

## 9\. 프로젝트 회고 및 배운 점

> 본 프로젝트는 단순한 모델 구현을 넘어, **실제 문제 해결을 위한 AI 개발의 전 과정을 깊이 있게 경험**하는 소중한 기회였습니다.

  - **데이터가 왕이다 (Data is King):** 최신 SOTA 모델을 사용하는 것보다, 주어진 데이터의 특성을 집요하게 파고들어 그에 맞는 전처리 및 증강 전략을 세우는 것이 성능에 훨씬 더 결정적인 영향을 미친다는 사실을 다시 한번 체감했습니다.
  - **체계적인 실험의 중요성:** 가설 수립 → 실험 설계 → 결과 분석 → 인사이트 도출의 과정을 반복하며, 감에 의존하는 튜닝이 아닌 데이터 기반의 의사결정을 내리는 훈련을 할 수 있었습니다.
  - **디테일의 차이:** 대회 규정(최고 신뢰도 1개 제출, 미탐지 시 처리 등)을 코드로 정확하게 구현하는 후처리 과정의 중요성을 깨달았습니다. 작은 디테일이 최종 순위를 결정할 수 있습니다.
  - **모델 너머의 고민:** AI 모델 개발은 단순히 코드를 짜는 행위를 넘어, 해결하고자 하는 도메인(여기서는 도로 환경)에 대한 이해를 바탕으로 최적의 접근법을 끊임없이 고민하고 탐색하는 과정이라는 것을 배웠습니다.

이번 챌린지를 통해 얻은 값진 경험과 교훈을 바탕으로, 앞으로 더 복잡하고 도전적인 AI 문제들을 해결해나가는 개발자로 성장하겠습니다.
